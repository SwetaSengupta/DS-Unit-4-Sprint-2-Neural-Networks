{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_422_Backprop_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "neural (Python3)",
      "language": "python",
      "name": "neural"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwetaSengupta/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_422_Backprop_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Backpropagation Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Using TensorFlow Keras, Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn.\n",
        "\n",
        "This is your \"Hello World!\" of TensorFlow.\n",
        "\n",
        "### Example TensorFlow Starter Code\n",
        "\n",
        "```python \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(3, activation='sigmoid', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)\n",
        "\n",
        "```\n",
        "\n",
        "### Additional Written Tasks:\n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nEREYT-3wI1f",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXBa9o3SeL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the input and output tables\n",
        "X = np.array([\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 1],\n",
        "    [1, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 0],\n",
        "    [1, 1, 1],\n",
        "    [0, 0, 0]\n",
        "])\n",
        "y = np.array([[0],[1],[1],[1],[1],[0],[0]])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMJpwqtiSegC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b32c404-694d-4169-87ba-e3efb3a3480e"
      },
      "source": [
        "# initialize the tensorflow model\n",
        "model = Sequential([\n",
        "    Dense(4, activation='sigmoid', input_dim=3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "# comple it\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae','mse'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2620 - mae: 0.5090 - mse: 0.2620\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2618 - mae: 0.5088 - mse: 0.2618\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2615 - mae: 0.5086 - mse: 0.2615\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2612 - mae: 0.5085 - mse: 0.2612\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2610 - mae: 0.5083 - mse: 0.2610\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2607 - mae: 0.5081 - mse: 0.2607\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2605 - mae: 0.5079 - mse: 0.2605\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2602 - mae: 0.5078 - mse: 0.2602\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2600 - mae: 0.5076 - mse: 0.2600\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2597 - mae: 0.5074 - mse: 0.2597\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2595 - mae: 0.5073 - mse: 0.2595\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2592 - mae: 0.5071 - mse: 0.2592\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2590 - mae: 0.5069 - mse: 0.2590\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2588 - mae: 0.5068 - mse: 0.2588\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2585 - mae: 0.5066 - mse: 0.2585\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2583 - mae: 0.5064 - mse: 0.2583\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2581 - mae: 0.5063 - mse: 0.2581\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2578 - mae: 0.5061 - mse: 0.2578\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.5059 - mse: 0.2576\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2574 - mae: 0.5058 - mse: 0.2574\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.5056 - mse: 0.2572\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2570 - mae: 0.5054 - mse: 0.2570\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2568 - mae: 0.5053 - mse: 0.2568\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2566 - mae: 0.5051 - mse: 0.2566\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2564 - mae: 0.5049 - mse: 0.2564\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2562 - mae: 0.5048 - mse: 0.2562\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2560 - mae: 0.5046 - mse: 0.2560\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2558 - mae: 0.5044 - mse: 0.2558\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2556 - mae: 0.5043 - mse: 0.2556\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2554 - mae: 0.5041 - mse: 0.2554\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2552 - mae: 0.5040 - mse: 0.2552\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2550 - mae: 0.5038 - mse: 0.2550\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 983us/step - loss: 0.2548 - mae: 0.5036 - mse: 0.2548\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2547 - mae: 0.5035 - mse: 0.2547\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2545 - mae: 0.5033 - mse: 0.2545\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2543 - mae: 0.5032 - mse: 0.2543\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2542 - mae: 0.5030 - mse: 0.2542\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2540 - mae: 0.5029 - mse: 0.2540\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2538 - mae: 0.5027 - mse: 0.2538\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2537 - mae: 0.5025 - mse: 0.2537\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2535 - mae: 0.5024 - mse: 0.2535\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2534 - mae: 0.5022 - mse: 0.2534\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2532 - mae: 0.5021 - mse: 0.2532\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2531 - mae: 0.5019 - mse: 0.2531\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2529 - mae: 0.5018 - mse: 0.2529\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2528 - mae: 0.5016 - mse: 0.2528\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2526 - mae: 0.5015 - mse: 0.2526\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2525 - mae: 0.5013 - mse: 0.2525\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2524 - mae: 0.5012 - mse: 0.2524\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2522 - mae: 0.5010 - mse: 0.2522\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.2521 - mae: 0.5009 - mse: 0.2521\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2520 - mae: 0.5008 - mse: 0.2520\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2518 - mae: 0.5006 - mse: 0.2518\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2517 - mae: 0.5005 - mse: 0.2517\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2516 - mae: 0.5003 - mse: 0.2516\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2515 - mae: 0.5002 - mse: 0.2515\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2513 - mae: 0.5001 - mse: 0.2513\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2512 - mae: 0.4999 - mse: 0.2512\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2511 - mae: 0.4998 - mse: 0.2511\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2510 - mae: 0.4996 - mse: 0.2510\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2509 - mae: 0.4995 - mse: 0.2509\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2508 - mae: 0.4994 - mse: 0.2508\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2507 - mae: 0.4992 - mse: 0.2507\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2505 - mae: 0.4991 - mse: 0.2505\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2504 - mae: 0.4990 - mse: 0.2504\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2503 - mae: 0.4988 - mse: 0.2503\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2502 - mae: 0.4987 - mse: 0.2502\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2501 - mae: 0.4986 - mse: 0.2501\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2500 - mae: 0.4985 - mse: 0.2500\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2499 - mae: 0.4983 - mse: 0.2499\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2498 - mae: 0.4982 - mse: 0.2498\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2497 - mae: 0.4981 - mse: 0.2497\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2497 - mae: 0.4980 - mse: 0.2497\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2496 - mae: 0.4978 - mse: 0.2496\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2495 - mae: 0.4977 - mse: 0.2495\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2494 - mae: 0.4976 - mse: 0.2494\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2493 - mae: 0.4975 - mse: 0.2493\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2492 - mae: 0.4973 - mse: 0.2492\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2491 - mae: 0.4972 - mse: 0.2491\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2490 - mae: 0.4971 - mse: 0.2490\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2490 - mae: 0.4970 - mse: 0.2490\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2489 - mae: 0.4969 - mse: 0.2489\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2488 - mae: 0.4968 - mse: 0.2488\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2487 - mae: 0.4966 - mse: 0.2487\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2486 - mae: 0.4965 - mse: 0.2486\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2486 - mae: 0.4964 - mse: 0.2486\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2485 - mae: 0.4963 - mse: 0.2485\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2484 - mae: 0.4962 - mse: 0.2484\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2483 - mae: 0.4961 - mse: 0.2483\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2483 - mae: 0.4960 - mse: 0.2483\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2482 - mae: 0.4959 - mse: 0.2482\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2481 - mae: 0.4958 - mse: 0.2481\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2480 - mae: 0.4957 - mse: 0.2480\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2480 - mae: 0.4955 - mse: 0.2480\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2479 - mae: 0.4954 - mse: 0.2479\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2478 - mae: 0.4953 - mse: 0.2478\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2478 - mae: 0.4952 - mse: 0.2478\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2477 - mae: 0.4951 - mse: 0.2477\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2476 - mae: 0.4950 - mse: 0.2476\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2476 - mae: 0.4949 - mse: 0.2476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk4hSGhaSejd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf923717-fad2-4122-f5c6-8dd7908414e4"
      },
      "source": [
        "# initialize the tensorflow model\n",
        "model = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=3),\n",
        "    Dense(1, activation='relu')\n",
        "])\n",
        "# comple it\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mae','mse'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1000us/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - mse: 0.5714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeJ79kXESD3W",
        "colab_type": "text"
      },
      "source": [
        "### Build a Tensor Keras Perceptron\n",
        "\n",
        "Try to match the architecture we used on Monday - inputs nodes and one output node. Apply this architecture to the XOR-ish dataset above. \n",
        "\n",
        "After fitting your model answer these questions: \n",
        "\n",
        "Are you able to achieve the same results as a bigger architecture from the first part of the assignment? Why is this disparity the case? What properties of the XOR dataset would cause this disparity? \n",
        "\n",
        "Now extrapolate this behavior on a much larger dataset in terms of features. What kind of architecture decisions could we make to avoid the problems the XOR dataset presents at scale? \n",
        "\n",
        "*Note:* The bias term is baked in by default in the Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX-Bu_brSD3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Completed in above section"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use TensorFlow Keras & the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the canonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the Internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
        "\n",
        "\n",
        "### Parts\n",
        "1. Gathering & Transforming the Data\n",
        "2. Making MNIST a Binary Problem\n",
        "3. Estimating your Neural Network (the part you focus on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVQylLzFSD3c",
        "colab_type": "text"
      },
      "source": [
        "### Gathering the Data \n",
        "\n",
        "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-PrMNK9SD3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMN0R2l0SD3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPaclYzESD3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e69655a5-647b-45f5-841f-0ba5aa455b01"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5bYR1_bUkVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66e6e2d6-b95e-4fd3-b972-91b415752b73"
      },
      "source": [
        "# reshape the y arrays\n",
        "y_train = np.array(y_train).reshape(60000,1)\n",
        "y_test = np.array(y_test).reshape(10000,1)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000, 1) (10000, 28, 28) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYNnkIokSD3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f09ac77-df60-4199-9e16-623b2c6a02f9"
      },
      "source": [
        "# Now the data should be in a format you're more familiar with\n",
        "X_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlGhNVmCU15q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c63a12b-1308-48d8-e4f6-daefe414393a"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdrktqwHThZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "dda5477f-1f9b-45df-845b-f7386d797a92"
      },
      "source": [
        "# show the first few images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(9):\n",
        "    # Define subplot\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    \n",
        "    # Plot raw pixel data\n",
        "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3gM01sLVYwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# initialize the tensorflow model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MVOYSxQVe09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8185f52b-26d5-4acf-e945-5c95d069eb39"
      },
      "source": [
        "# set up early stopping\n",
        "callback=EarlyStopping(patience=3,verbose=1)\n",
        "\n",
        "# compile it\n",
        "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 5495      \n",
            "=================================================================\n",
            "Total params: 5,495\n",
            "Trainable params: 5,495\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lxf_GdBVkf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4b3d1ba1-6e35-4467-9845-54fa0dc97c72"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X_train,y_train,\n",
        "         epochs=20,\n",
        "         validation_data=(X_test,y_test),\n",
        "         callbacks=[callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4ff68acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpwBpD2SD3y",
        "colab_type": "text"
      },
      "source": [
        "### Making MNIST a Binary Problem \n",
        "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simplify the problem for now: Zero or all else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyKfH1nESD3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_temp = np.zeros(y_train.shape)\n",
        "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
        "y_train = y_temp\n",
        "\n",
        "y_temp = np.zeros(y_test.shape)\n",
        "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
        "y_test = y_temp"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ydDb0rSD33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ccdee15c-3faa-4591-99f1-39a5a7943ad3"
      },
      "source": [
        "# A Nice Binary target for ya to work with\n",
        "y_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z4hPtxGSD36",
        "colab_type": "text"
      },
      "source": [
        "### Estimating Your `net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MOPtYdk1HgA",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}