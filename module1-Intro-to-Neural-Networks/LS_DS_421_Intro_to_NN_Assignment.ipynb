{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "https://www.wandb.com/articles/fundamentals-of-neural-networks\n",
    "\n",
    "https://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html\n",
    "\n",
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: \n",
    "This is the layer which takes input from the dataset. So this layer takes the initial data for the neural network.\n",
    "### Hidden Layer: \n",
    "This is layer which is between input layer and the output layer and also the stage where activation function is applied and then the results are passed on to the next layer. There are often multiple hidden layers in a network.\n",
    "### Output Layer:\n",
    " This is the final layer in the network. Output layer produces the result for given inputs, ie. this layer shows what the actual prediction for the function is.\n",
    "### Neuron:\n",
    "The basic unit of computation in a neural network is the neuron\n",
    "### Weight:\n",
    "The weight show how important the output for each node plays in determining the output of the function. Wieghts can also be defined as parameters\n",
    "### Activation Function:\n",
    "activation function defines if given node should be “activated” or not based on the weighted sum.\n",
    "### Node Map:\n",
    "The Node Map is a visual diagram that shows how the neural network works. How the outputs of of node move on to the next node so that you can have an idea of how it works\n",
    "### Perceptron:\n",
    "The simplest kind of neural network that only has a single node that can take any number of inputs and spit out an output.\n",
    "A perceptron follows the “feed-forward” model, meaning inputs are sent into the neuron, are processed, and result in an output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here\n",
    "https://natureofcode.com/book/chapter-10-neural-networks/\n",
    "\n",
    "The information starts out in the dataset and and is put into the input layer of the neural network the network then takes that information and uses an activation function to pass it to the first hidden layer where it is multiplied by the weight and then passed to the next hidden layer until it hits the output layer where it adds the bias and the spits out a human readable prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(812)\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "# define the sigmoid and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0099616 ],\n",
       "       [0.21185521]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the random weights for the inputs\n",
    "weights = 2 * np.random.random((2,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs from the output\n",
    "inputs = df[[\"x1\",\"x2\"]]\n",
    "correct_out = [[1],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-4.66977654]\n",
      " [-4.66353102]]\n",
      "Output after training\n",
      "[[0.99908895]\n",
      " [0.91134627]\n",
      " [0.91185586]\n",
      " [0.08840182]]\n"
     ]
    }
   ],
   "source": [
    "# create a for loop to update our weights 1,000 times\n",
    "for iteration in range(1000):\n",
    "    # weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights) + 7\n",
    "    # activate\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    # calculate error\n",
    "    error = correct_out - activated_output\n",
    "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "    # Update the weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "#     breakpoint()\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "print(diabetes.shape)\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>0.402628</td>\n",
       "      <td>0.195722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.279603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.555984</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.261144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.924097</td>\n",
       "      <td>0.323181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.161591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>0.152076</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.185797</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.138852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.731335</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.143655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.033552  0.827625       0.402628       0.195722  0.000000  0.187893   \n",
       "1     0.008424  0.716040       0.555984       0.244296  0.000000  0.224079   \n",
       "2     0.040398  0.924097       0.323181       0.000000  0.000000  0.117658   \n",
       "3     0.006612  0.588467       0.436392       0.152076  0.621527  0.185797   \n",
       "4     0.000000  0.596386       0.174127       0.152361  0.731335  0.187622   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  \n",
       "0                  0.003506  0.279603  \n",
       "1                  0.002957  0.261144  \n",
       "2                  0.003393  0.161591  \n",
       "3                  0.001104  0.138852  \n",
       "4                  0.009960  0.143655  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "X = diabetes[feats]\n",
    "y = diabetes['Outcome']\n",
    "transformer = Normalizer().fit(X)\n",
    "X = pd.DataFrame(transformer.transform(X))\n",
    "X.columns = feats\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(y).reshape(768,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "#https://towardsdatascience.com/perceptron-explanation-implementation-and-a-visual-example-3c8e76b4e2d1\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = sigmoid(x)\n",
    "        return sx * (1 - sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Randomly Initialize Weights\n",
    "        weights = 2 * np.random.random((len(X.columns),1)) - 1\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            # Weighted sum of inputs / weights\n",
    "            weighted_sum = np.dot(X, weights) + 10.969\n",
    "            # Activate!\n",
    "            activated_output = sigmoid(weighted_sum)\n",
    "            # Cac error\n",
    "            error = y - activated_output\n",
    "            adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "            # Update the Weights\n",
    "            weights += np.dot(X.T, adjustments)\n",
    "            \n",
    "        self.weights = weights\n",
    "        self.activated_output = activated_output\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        print(self.activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99998385]\n",
      " [0.99998372]\n",
      " [0.99998483]\n",
      " [0.99996998]\n",
      " [0.99996349]\n",
      " [0.99998579]\n",
      " [0.99996779]\n",
      " [0.99998297]\n",
      " [0.99995879]\n",
      " [0.99998771]\n",
      " [0.99998577]\n",
      " [0.99998496]\n",
      " [0.99998658]\n",
      " [0.9999575 ]\n",
      " [0.99997007]\n",
      " [0.9999833 ]\n",
      " [0.99996172]\n",
      " [0.99998597]\n",
      " [0.99996757]\n",
      " [0.99997161]\n",
      " [0.9999627 ]\n",
      " [0.99998683]\n",
      " [0.99998499]\n",
      " [0.99998384]\n",
      " [0.99997189]\n",
      " [0.99997216]\n",
      " [0.99998539]\n",
      " [0.999967  ]\n",
      " [0.99997615]\n",
      " [0.99998613]\n",
      " [0.99998512]\n",
      " [0.99996339]\n",
      " [0.99997641]\n",
      " [0.99998686]\n",
      " [0.99998477]\n",
      " [0.99996311]\n",
      " [0.99998568]\n",
      " [0.99998436]\n",
      " [0.99998199]\n",
      " [0.99996412]\n",
      " [0.99997646]\n",
      " [0.99998555]\n",
      " [0.99998621]\n",
      " [0.99996821]\n",
      " [0.99998523]\n",
      " [0.99998176]\n",
      " [0.99998439]\n",
      " [0.99998369]\n",
      " [0.99998319]\n",
      " [0.99998439]\n",
      " [0.99997514]\n",
      " [0.99997867]\n",
      " [0.99998164]\n",
      " [0.99996478]\n",
      " [0.99996027]\n",
      " [0.99998447]\n",
      " [0.99996259]\n",
      " [0.99996829]\n",
      " [0.99998519]\n",
      " [0.99996391]\n",
      " [0.99998413]\n",
      " [0.99998566]\n",
      " [0.99998763]\n",
      " [0.99996839]\n",
      " [0.99998592]\n",
      " [0.99998426]\n",
      " [0.99998419]\n",
      " [0.99998631]\n",
      " [0.99997976]\n",
      " [0.99997395]\n",
      " [0.99997191]\n",
      " [0.99996796]\n",
      " [0.99998615]\n",
      " [0.99996265]\n",
      " [0.99998328]\n",
      " [0.99998434]\n",
      " [0.99998731]\n",
      " [0.99998312]\n",
      " [0.99998156]\n",
      " [0.99998374]\n",
      " [0.99998361]\n",
      " [0.99998445]\n",
      " [0.99997569]\n",
      " [0.99998311]\n",
      " [0.99998559]\n",
      " [0.99996866]\n",
      " [0.99998312]\n",
      " [0.99997358]\n",
      " [0.99997298]\n",
      " [0.99998394]\n",
      " [0.99998565]\n",
      " [0.99996768]\n",
      " [0.99997725]\n",
      " [0.99998641]\n",
      " [0.9999776 ]\n",
      " [0.99996476]\n",
      " [0.99998297]\n",
      " [0.99997007]\n",
      " [0.99997259]\n",
      " [0.9999625 ]\n",
      " [0.99998446]\n",
      " [0.99998429]\n",
      " [0.99998561]\n",
      " [0.99997876]\n",
      " [0.99998517]\n",
      " [0.99996526]\n",
      " [0.99998678]\n",
      " [0.99996899]\n",
      " [0.9999798 ]\n",
      " [0.99997922]\n",
      " [0.99997018]\n",
      " [0.99995896]\n",
      " [0.99997789]\n",
      " [0.99998561]\n",
      " [0.99996706]\n",
      " [0.99998636]\n",
      " [0.99998562]\n",
      " [0.99998517]\n",
      " [0.99998347]\n",
      " [0.99997835]\n",
      " [0.9999708 ]\n",
      " [0.99998233]\n",
      " [0.99997053]\n",
      " [0.99998679]\n",
      " [0.99998498]\n",
      " [0.99996264]\n",
      " [0.99996779]\n",
      " [0.99996966]\n",
      " [0.99996975]\n",
      " [0.99998692]\n",
      " [0.99996969]\n",
      " [0.99998526]\n",
      " [0.99996402]\n",
      " [0.99998429]\n",
      " [0.99997845]\n",
      " [0.99996792]\n",
      " [0.99997628]\n",
      " [0.99996953]\n",
      " [0.99998517]\n",
      " [0.99995941]\n",
      " [0.99998654]\n",
      " [0.99998407]\n",
      " [0.99997338]\n",
      " [0.99998624]\n",
      " [0.99996103]\n",
      " [0.99998493]\n",
      " [0.99998481]\n",
      " [0.99996829]\n",
      " [0.99998617]\n",
      " [0.99998432]\n",
      " [0.9999626 ]\n",
      " [0.99998597]\n",
      " [0.99997082]\n",
      " [0.99995768]\n",
      " [0.99998471]\n",
      " [0.99998279]\n",
      " [0.99997018]\n",
      " [0.99996655]\n",
      " [0.99997686]\n",
      " [0.99997339]\n",
      " [0.99998367]\n",
      " [0.99997128]\n",
      " [0.99996009]\n",
      " [0.99998332]\n",
      " [0.99998543]\n",
      " [0.99996842]\n",
      " [0.99998295]\n",
      " [0.99998551]\n",
      " [0.99998533]\n",
      " [0.99997676]\n",
      " [0.99998633]\n",
      " [0.99996995]\n",
      " [0.99997987]\n",
      " [0.99997291]\n",
      " [0.99997572]\n",
      " [0.99997151]\n",
      " [0.99998682]\n",
      " [0.99996959]\n",
      " [0.99998533]\n",
      " [0.99998549]\n",
      " [0.99998679]\n",
      " [0.99997188]\n",
      " [0.999981  ]\n",
      " [0.99998621]\n",
      " [0.99998558]\n",
      " [0.99998344]\n",
      " [0.99995986]\n",
      " [0.9999777 ]\n",
      " [0.99997022]\n",
      " [0.9999675 ]\n",
      " [0.99998517]\n",
      " [0.99997263]\n",
      " [0.99998505]\n",
      " [0.99998276]\n",
      " [0.99998529]\n",
      " [0.9999652 ]\n",
      " [0.99998493]\n",
      " [0.99997817]\n",
      " [0.99996905]\n",
      " [0.99996044]\n",
      " [0.99998409]\n",
      " [0.99998479]\n",
      " [0.99998416]\n",
      " [0.99997918]\n",
      " [0.99996578]\n",
      " [0.99998396]\n",
      " [0.99996556]\n",
      " [0.99998593]\n",
      " [0.99997038]\n",
      " [0.99998368]\n",
      " [0.99998376]\n",
      " [0.99998148]\n",
      " [0.99998467]\n",
      " [0.99996843]\n",
      " [0.99996672]\n",
      " [0.99996247]\n",
      " [0.9999661 ]\n",
      " [0.99997018]\n",
      " [0.99998484]\n",
      " [0.99998559]\n",
      " [0.99995797]\n",
      " [0.99998617]\n",
      " [0.99998364]\n",
      " [0.9999673 ]\n",
      " [0.99997699]\n",
      " [0.99997909]\n",
      " [0.9999852 ]\n",
      " [0.99998159]\n",
      " [0.999957  ]\n",
      " [0.99997634]\n",
      " [0.99998465]\n",
      " [0.99996007]\n",
      " [0.99997907]\n",
      " [0.99998505]\n",
      " [0.99997641]\n",
      " [0.99998414]\n",
      " [0.99996986]\n",
      " [0.99998294]\n",
      " [0.99998435]\n",
      " [0.99998594]\n",
      " [0.99998326]\n",
      " [0.99997065]\n",
      " [0.9999844 ]\n",
      " [0.99996492]\n",
      " [0.99996514]\n",
      " [0.99998499]\n",
      " [0.99998601]\n",
      " [0.99995697]\n",
      " [0.99995895]\n",
      " [0.9999843 ]\n",
      " [0.99998592]\n",
      " [0.99998542]\n",
      " [0.99997799]\n",
      " [0.99998263]\n",
      " [0.99996352]\n",
      " [0.99998209]\n",
      " [0.99998226]\n",
      " [0.99998368]\n",
      " [0.99996052]\n",
      " [0.99997131]\n",
      " [0.99997295]\n",
      " [0.99998244]\n",
      " [0.99998314]\n",
      " [0.99998547]\n",
      " [0.99998523]\n",
      " [0.99997707]\n",
      " [0.99998184]\n",
      " [0.99998158]\n",
      " [0.99998466]\n",
      " [0.99998251]\n",
      " [0.99998388]\n",
      " [0.999975  ]\n",
      " [0.99998611]\n",
      " [0.99997471]\n",
      " [0.99998681]\n",
      " [0.99997323]\n",
      " [0.999984  ]\n",
      " [0.99996835]\n",
      " [0.99998679]\n",
      " [0.99996097]\n",
      " [0.99998439]\n",
      " [0.99997162]\n",
      " [0.99997058]\n",
      " [0.99998579]\n",
      " [0.99998663]\n",
      " [0.99997177]\n",
      " [0.99995786]\n",
      " [0.9999628 ]\n",
      " [0.99997735]\n",
      " [0.99997331]\n",
      " [0.99997812]\n",
      " [0.99997229]\n",
      " [0.99996498]\n",
      " [0.99996078]\n",
      " [0.99998548]\n",
      " [0.99997041]\n",
      " [0.99995941]\n",
      " [0.99996392]\n",
      " [0.99996705]\n",
      " [0.99998703]\n",
      " [0.99998225]\n",
      " [0.99996784]\n",
      " [0.99997797]\n",
      " [0.99998523]\n",
      " [0.99998554]\n",
      " [0.99997051]\n",
      " [0.99997271]\n",
      " [0.99996846]\n",
      " [0.99996546]\n",
      " [0.99996367]\n",
      " [0.99998467]\n",
      " [0.99996455]\n",
      " [0.99997456]\n",
      " [0.99997266]\n",
      " [0.99998441]\n",
      " [0.99997179]\n",
      " [0.99997804]\n",
      " [0.99998453]\n",
      " [0.99996604]\n",
      " [0.99998564]\n",
      " [0.99996372]\n",
      " [0.99998332]\n",
      " [0.9999842 ]\n",
      " [0.99998231]\n",
      " [0.99998276]\n",
      " [0.999968  ]\n",
      " [0.99996568]\n",
      " [0.99998491]\n",
      " [0.99996848]\n",
      " [0.99997544]\n",
      " [0.99998549]\n",
      " [0.99997588]\n",
      " [0.99998237]\n",
      " [0.99998709]\n",
      " [0.99997535]\n",
      " [0.99996202]\n",
      " [0.99998308]\n",
      " [0.99998615]\n",
      " [0.99996804]\n",
      " [0.99998507]\n",
      " [0.99997234]\n",
      " [0.99997542]\n",
      " [0.99998303]\n",
      " [0.99998572]\n",
      " [0.99998686]\n",
      " [0.99997358]\n",
      " [0.9999727 ]\n",
      " [0.9999826 ]\n",
      " [0.99997408]\n",
      " [0.9999848 ]\n",
      " [0.99998557]\n",
      " [0.9999854 ]\n",
      " [0.99998523]\n",
      " [0.99997823]\n",
      " [0.9999851 ]\n",
      " [0.99998591]\n",
      " [0.99996322]\n",
      " [0.99998155]\n",
      " [0.99997776]\n",
      " [0.99996457]\n",
      " [0.99996162]\n",
      " [0.9999859 ]\n",
      " [0.99998539]\n",
      " [0.99998605]\n",
      " [0.99996189]\n",
      " [0.99997126]\n",
      " [0.99998554]\n",
      " [0.99998404]\n",
      " [0.99997641]\n",
      " [0.99997189]\n",
      " [0.99995828]\n",
      " [0.99997341]\n",
      " [0.99997282]\n",
      " [0.99996872]\n",
      " [0.99996354]\n",
      " [0.99996224]\n",
      " [0.99997415]\n",
      " [0.9999699 ]\n",
      " [0.99998442]\n",
      " [0.99997526]\n",
      " [0.99997253]\n",
      " [0.99998387]\n",
      " [0.99996464]\n",
      " [0.99997543]\n",
      " [0.999971  ]\n",
      " [0.99997754]\n",
      " [0.99998394]\n",
      " [0.99998456]\n",
      " [0.99996424]\n",
      " [0.9999731 ]\n",
      " [0.99996372]\n",
      " [0.9999843 ]\n",
      " [0.99995889]\n",
      " [0.99997554]\n",
      " [0.99998495]\n",
      " [0.99996061]\n",
      " [0.9999683 ]\n",
      " [0.99998177]\n",
      " [0.9999863 ]\n",
      " [0.99998263]\n",
      " [0.99998565]\n",
      " [0.99998606]\n",
      " [0.99997416]\n",
      " [0.99998539]\n",
      " [0.99998486]\n",
      " [0.99996324]\n",
      " [0.99998617]\n",
      " [0.99998538]\n",
      " [0.99998502]\n",
      " [0.99995672]\n",
      " [0.99998355]\n",
      " [0.99996431]\n",
      " [0.99996112]\n",
      " [0.99997704]\n",
      " [0.9999645 ]\n",
      " [0.99995881]\n",
      " [0.99998378]\n",
      " [0.99998356]\n",
      " [0.99998631]\n",
      " [0.99997015]\n",
      " [0.99996534]\n",
      " [0.99997348]\n",
      " [0.99996976]\n",
      " [0.99998323]\n",
      " [0.99996561]\n",
      " [0.9999632 ]\n",
      " [0.99998401]\n",
      " [0.99996781]\n",
      " [0.99996813]\n",
      " [0.99996606]\n",
      " [0.99998265]\n",
      " [0.99997433]\n",
      " [0.99997625]\n",
      " [0.9999852 ]\n",
      " [0.99998569]\n",
      " [0.99998179]\n",
      " [0.99998425]\n",
      " [0.99998507]\n",
      " [0.99998468]\n",
      " [0.99998593]\n",
      " [0.99998417]\n",
      " [0.99997586]\n",
      " [0.99996864]\n",
      " [0.99998596]\n",
      " [0.99998445]\n",
      " [0.99997918]\n",
      " [0.99997596]\n",
      " [0.99997014]\n",
      " [0.99997291]\n",
      " [0.99997656]\n",
      " [0.99997088]\n",
      " [0.9999848 ]\n",
      " [0.9999608 ]\n",
      " [0.99998514]\n",
      " [0.99996757]\n",
      " [0.99998361]\n",
      " [0.99998581]\n",
      " [0.99997324]\n",
      " [0.99996492]\n",
      " [0.99998034]\n",
      " [0.99997961]\n",
      " [0.99998623]\n",
      " [0.99997667]\n",
      " [0.99998463]\n",
      " [0.99998676]\n",
      " [0.99997092]\n",
      " [0.99997796]\n",
      " [0.99996821]\n",
      " [0.99998353]\n",
      " [0.99996888]\n",
      " [0.99998246]\n",
      " [0.99998211]\n",
      " [0.99998248]\n",
      " [0.99998637]\n",
      " [0.99998511]\n",
      " [0.99998491]\n",
      " [0.99996322]\n",
      " [0.99997266]\n",
      " [0.99997566]\n",
      " [0.99998513]\n",
      " [0.999961  ]\n",
      " [0.99998313]\n",
      " [0.99997646]\n",
      " [0.9999672 ]\n",
      " [0.99998183]\n",
      " [0.99996045]\n",
      " [0.99995663]\n",
      " [0.99996462]\n",
      " [0.99998479]\n",
      " [0.99998589]\n",
      " [0.99997279]\n",
      " [0.99998474]\n",
      " [0.99998303]\n",
      " [0.99997199]\n",
      " [0.99998441]\n",
      " [0.99998607]\n",
      " [0.99998574]\n",
      " [0.9999738 ]\n",
      " [0.99997263]\n",
      " [0.99996693]\n",
      " [0.99997667]\n",
      " [0.99998319]\n",
      " [0.9999839 ]\n",
      " [0.99997411]\n",
      " [0.99998346]\n",
      " [0.99998712]\n",
      " [0.99997607]\n",
      " [0.99996509]\n",
      " [0.99997012]\n",
      " [0.99998707]\n",
      " [0.99998524]\n",
      " [0.9999641 ]\n",
      " [0.99998749]\n",
      " [0.99998533]\n",
      " [0.99997132]\n",
      " [0.99997362]\n",
      " [0.99997032]\n",
      " [0.99998627]\n",
      " [0.99998702]\n",
      " [0.99996459]\n",
      " [0.99997302]\n",
      " [0.99996912]\n",
      " [0.99998426]\n",
      " [0.99998588]\n",
      " [0.99998456]\n",
      " [0.9999842 ]\n",
      " [0.99997264]\n",
      " [0.9999722 ]\n",
      " [0.99996309]\n",
      " [0.99998542]\n",
      " [0.99997051]\n",
      " [0.9999846 ]\n",
      " [0.99997126]\n",
      " [0.99998324]\n",
      " [0.99997282]\n",
      " [0.99998218]\n",
      " [0.99998647]\n",
      " [0.99998803]\n",
      " [0.99996307]\n",
      " [0.9999676 ]\n",
      " [0.99996314]\n",
      " [0.99996506]\n",
      " [0.99998548]\n",
      " [0.99997728]\n",
      " [0.99997352]\n",
      " [0.99996709]\n",
      " [0.99996819]\n",
      " [0.99996683]\n",
      " [0.9999774 ]\n",
      " [0.99998426]\n",
      " [0.99998311]\n",
      " [0.99996838]\n",
      " [0.9999872 ]\n",
      " [0.99997658]\n",
      " [0.99996748]\n",
      " [0.99996421]\n",
      " [0.99998232]\n",
      " [0.99998699]\n",
      " [0.99998324]\n",
      " [0.99998685]\n",
      " [0.99998624]\n",
      " [0.99996307]\n",
      " [0.99997106]\n",
      " [0.99997724]\n",
      " [0.99998569]\n",
      " [0.99997101]\n",
      " [0.99998029]\n",
      " [0.9999685 ]\n",
      " [0.99997145]\n",
      " [0.9999655 ]\n",
      " [0.99998644]\n",
      " [0.99998564]\n",
      " [0.99997653]\n",
      " [0.99996756]\n",
      " [0.99996078]\n",
      " [0.9999715 ]\n",
      " [0.99996767]\n",
      " [0.99998467]\n",
      " [0.99998578]\n",
      " [0.99998081]\n",
      " [0.999982  ]\n",
      " [0.99998363]\n",
      " [0.99998629]\n",
      " [0.99998625]\n",
      " [0.99995857]\n",
      " [0.99998438]\n",
      " [0.99998535]\n",
      " [0.99998594]\n",
      " [0.9999717 ]\n",
      " [0.99998285]\n",
      " [0.99998386]\n",
      " [0.99996573]\n",
      " [0.99998571]\n",
      " [0.99996625]\n",
      " [0.99996228]\n",
      " [0.99996891]\n",
      " [0.99998622]\n",
      " [0.99997688]\n",
      " [0.99998463]\n",
      " [0.99996684]\n",
      " [0.99998457]\n",
      " [0.99998335]\n",
      " [0.9999831 ]\n",
      " [0.99997292]\n",
      " [0.99998283]\n",
      " [0.99998202]\n",
      " [0.99996164]\n",
      " [0.99997784]\n",
      " [0.99996174]\n",
      " [0.99996468]\n",
      " [0.99996447]\n",
      " [0.99996685]\n",
      " [0.99996225]\n",
      " [0.99998396]\n",
      " [0.99997098]\n",
      " [0.99998568]\n",
      " [0.99998617]\n",
      " [0.99998288]\n",
      " [0.99998555]\n",
      " [0.99998193]\n",
      " [0.99996593]\n",
      " [0.99998476]\n",
      " [0.99998527]\n",
      " [0.99996726]\n",
      " [0.99998485]\n",
      " [0.99997596]\n",
      " [0.99998483]\n",
      " [0.99998471]\n",
      " [0.9999859 ]\n",
      " [0.99998391]\n",
      " [0.99998579]\n",
      " [0.99997081]\n",
      " [0.99998497]\n",
      " [0.99996651]\n",
      " [0.99998638]\n",
      " [0.99998655]\n",
      " [0.99998656]\n",
      " [0.99997547]\n",
      " [0.99997213]\n",
      " [0.99997955]\n",
      " [0.99997234]\n",
      " [0.99998484]\n",
      " [0.99998596]\n",
      " [0.99998316]\n",
      " [0.99996612]\n",
      " [0.99995856]\n",
      " [0.99997125]\n",
      " [0.99996665]\n",
      " [0.99997187]\n",
      " [0.99998305]\n",
      " [0.99996817]\n",
      " [0.99996993]\n",
      " [0.99997375]\n",
      " [0.99998479]\n",
      " [0.99996663]\n",
      " [0.99995703]\n",
      " [0.99996973]\n",
      " [0.99996388]\n",
      " [0.9999867 ]\n",
      " [0.99997421]\n",
      " [0.99998614]\n",
      " [0.9999818 ]\n",
      " [0.99996669]\n",
      " [0.99997056]\n",
      " [0.99998301]\n",
      " [0.99996703]\n",
      " [0.99998558]\n",
      " [0.99998474]\n",
      " [0.99996346]\n",
      " [0.999975  ]\n",
      " [0.9999695 ]\n",
      " [0.99998424]\n",
      " [0.99998125]\n",
      " [0.9999628 ]\n",
      " [0.99998746]\n",
      " [0.99998449]\n",
      " [0.99998629]\n",
      " [0.9999848 ]\n",
      " [0.99998427]\n",
      " [0.99996042]\n",
      " [0.99997435]\n",
      " [0.99998202]\n",
      " [0.99996664]\n",
      " [0.99998535]\n",
      " [0.99998752]\n",
      " [0.99996412]\n",
      " [0.99998493]\n",
      " [0.9999834 ]\n",
      " [0.9999662 ]\n",
      " [0.99996647]\n",
      " [0.99998648]\n",
      " [0.99998614]\n",
      " [0.99997103]\n",
      " [0.99996921]\n",
      " [0.99998563]\n",
      " [0.99995994]\n",
      " [0.99997251]\n",
      " [0.9999822 ]\n",
      " [0.99996972]\n",
      " [0.99998466]\n",
      " [0.99996412]\n",
      " [0.99998466]\n",
      " [0.99998417]\n",
      " [0.99998277]\n",
      " [0.99997247]\n",
      " [0.99998337]\n",
      " [0.99998477]\n",
      " [0.99995842]\n",
      " [0.99998555]\n",
      " [0.99996313]\n",
      " [0.99996001]\n",
      " [0.9999822 ]\n",
      " [0.99998307]\n",
      " [0.99996034]\n",
      " [0.99998586]\n",
      " [0.99995975]\n",
      " [0.99996718]\n",
      " [0.99998647]\n",
      " [0.99996153]\n",
      " [0.99998495]\n",
      " [0.99998543]\n",
      " [0.99996168]\n",
      " [0.99997106]\n",
      " [0.99997306]\n",
      " [0.99998633]\n",
      " [0.99998316]\n",
      " [0.9999648 ]\n",
      " [0.99998335]\n",
      " [0.99998487]\n",
      " [0.9999848 ]\n",
      " [0.99997581]\n",
      " [0.99998575]\n",
      " [0.99997185]\n",
      " [0.99996349]\n",
      " [0.99998677]\n",
      " [0.99998275]\n",
      " [0.99997067]\n",
      " [0.99998559]\n",
      " [0.99996426]\n",
      " [0.9999857 ]\n",
      " [0.99996914]\n",
      " [0.99996934]\n",
      " [0.99996849]\n",
      " [0.99998624]\n",
      " [0.99997133]\n",
      " [0.99997348]\n",
      " [0.99998248]\n",
      " [0.99997405]\n",
      " [0.99996764]\n",
      " [0.9999855 ]\n",
      " [0.99998477]\n",
      " [0.99997383]\n",
      " [0.99998356]\n",
      " [0.99995812]\n",
      " [0.99998409]\n",
      " [0.99997188]\n",
      " [0.99998382]\n",
      " [0.99998571]\n",
      " [0.99998511]\n",
      " [0.99998581]\n",
      " [0.99998064]\n",
      " [0.99998352]\n",
      " [0.99998663]\n",
      " [0.99996677]\n",
      " [0.99998311]\n",
      " [0.99997155]\n",
      " [0.99998548]\n",
      " [0.99998301]]\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(200)\n",
    "perceptron.fit(X,y)\n",
    "perceptron.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Neural (Python3)",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
